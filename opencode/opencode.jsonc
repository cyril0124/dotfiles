{
  "$schema": "https://opencode.ai/config.json",

  "plugin": [
    // "oh-my-opencode@3.0.0-beta.8",
    // "opencode-antigravity-auth@1.2.8",
    "@tarquinen/opencode-dcp@1.2.3"
  ],

  "model": "nvidia/z-ai/glm4.7",
  // "model": "anthropic/claude-sonnet-4-5-20250929",
  "small_model": "nvidia/minimaxai/minimax-m2.1",

  "instructions": ["CLAUDE.md"],

  "permission": {
    "bash": {
      "*": "allow",
      "sudo *": "ask",
      "su *": "ask",
      "passwd *": "ask",
      "shutdown *": "deny",
      "reboot *": "deny",
      "halt *": "deny",
      "poweroff *": "deny",
      "systemctl reboot": "deny",
      "systemctl poweroff": "deny",
      "systemctl halt": "deny",
      "rm -rf /": "deny",
      "rm -rf /*": "deny",
      "dd if=/dev/zero of=/dev/*": "deny",
      "mkfs *": "deny",
      "fdisk *": "deny",
      "parted *": "deny",
      "git commit *": "ask",
      "git push *": "ask",
      "git merge *": "ask",
      "git rebase *": "ask",
      "git reset *": "ask",
      "git revert *": "ask",
      "git cherry-pick *": "ask",
      "git tag *": "ask",
      "chmod 777 *": "deny",
      "chown root *": "deny"
    },
    "edit": "allow",
    "webfetch": "allow"
  },

  "provider": {
    "google": {
      "models": {
        "antigravity-gemini-3-pro": {
          "name": "Gemini 3 Pro (Antigravity)",
          "limit": { "context": 1048576, "output": 65535 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] },
          "variants": {
            "low": { "thinkingLevel": "low" },
            "high": { "thinkingLevel": "high" }
          }
        },
        "antigravity-gemini-3-flash": {
          "name": "Gemini 3 Flash (Antigravity)",
          "limit": { "context": 1048576, "output": 65536 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] },
          "variants": {
            "minimal": { "thinkingLevel": "minimal" },
            "low": { "thinkingLevel": "low" },
            "medium": { "thinkingLevel": "medium" },
            "high": { "thinkingLevel": "high" }
          }
        },
        "antigravity-claude-sonnet-4-5": {
          "name": "Claude Sonnet 4.5 (Antigravity)",
          "limit": { "context": 200000, "output": 64000 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] }
        },
        "antigravity-claude-sonnet-4-5-thinking": {
          "name": "Claude Sonnet 4.5 Thinking (Antigravity)",
          "limit": { "context": 200000, "output": 64000 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] },
          "variants": {
            "low": { "thinkingConfig": { "thinkingBudget": 8192 } },
            "max": { "thinkingConfig": { "thinkingBudget": 32768 } }
          }
        },
        "antigravity-claude-opus-4-5-thinking": {
          "name": "Claude Opus 4.5 Thinking (Antigravity)",
          "limit": { "context": 200000, "output": 64000 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] },
          "variants": {
            "low": { "thinkingConfig": { "thinkingBudget": 8192 } },
            "max": { "thinkingConfig": { "thinkingBudget": 32768 } }
          }
        },
        "gemini-2.5-flash": {
          "name": "Gemini 2.5 Flash (Gemini CLI)",
          "limit": { "context": 1048576, "output": 65536 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] }
        },
        "gemini-2.5-pro": {
          "name": "Gemini 2.5 Pro (Gemini CLI)",
          "limit": { "context": 1048576, "output": 65536 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] }
        },
        "gemini-3-flash-preview": {
          "name": "Gemini 3 Flash Preview (Gemini CLI)",
          "limit": { "context": 1048576, "output": 65536 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] }
        },
        "gemini-3-pro-preview": {
          "name": "Gemini 3 Pro Preview (Gemini CLI)",
          "limit": { "context": 1048576, "output": 65535 },
          "modalities": { "input": ["text", "image", "pdf"], "output": ["text"] }
        }
      }
    },

    "nvidia": {
        "models": {
            "z-ai/glm4.7": {
              "limit": {
                "context": 204800,
                "output": 131100
              }
            },
            "minimaxai/minimax-m2.1": {
              "limit": {
                "context": 204800,
                "output": 131100
              }
            }
        }
    },

    "cliproxy": {
      "name": "cliproxy",
      "options": {
        "baseURL": "{env:CLIPROXY_BASE_URL}",
        // API key for local cliproxy service (placeholder/test key)
        "apiKey": "{env:CLIPROXY_API_KEY}"
      },
      "models": {
        // GLM-4.7 context and output limits from LLM Stats (https://llm-stats.com/models/glm-4.7)
        // Max Input: 204.8K (204,800 tokens) via Novita provider
        // Max Output: 131.1K (131,100 tokens) via Novita provider
        "glm-4.7": {
          "limit": {
            "context": 204800,
            "output": 131100
          }
        },
        // MiniMax M2.1 context and output limits
        // Context: 204,800 tokens from Jarvis Labs vLLM deployment guide (https://docs.jarvislabs.ai/blog/minimax-m21-vllm-deployment-guide)
        // Output: 131,072 tokens from Jarvis Labs vLLM deployment guide (https://docs.jarvislabs.ai/blog/minimax-m21-vllm-deployment-guide)
        // Note: LLM Stats shows 1.0M but this appears to be incorrect; multiple sources confirm ~204K context window
        "minimax-m2.1": {
          "limit": {
            "context": 204800,
            "output": 131072
          }
        },

        // Provided by Github Copilot
        // See https://github.com/em4go/CLIProxyAPI/blob/3a9ac7ef331da59da78d8504cab00a639f837cb7/internal/registry/model_definitions.go#L988
        "gpt-4.1": {
          "limit": {
            "context": 128000,
            "output": 16384
          }
        },
        "grok-code-fast-1": {
          "limit": {
            "context": 128000,
            "output": 16384
          }
        }
        // ,
        // "claude-opus-4.5": {
        //   "limit": {
        //     "context": 200000,
        //     "output": 64000
        //   }
        // }

      }
    }
  },

  "lsp": {
    "lua-ls": {
      "disabled": true
    },
    "emmylua": {
      "command": ["emmylua_ls"],
      "extensions": [".lua"]
    }
  },

  "mcp": {
    // Sequential Thinking MCP Server - Official implementation by Anthropic
    // Facilitates structured, step-by-step thinking process for complex problem-solving
    // GitHub: https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking
    // NPM: https://www.npmjs.com/package/@modelcontextprotocol/server-sequential-thinking
    // "sequential-thinking": {
    //   "type": "local",
    //   "command": ["npx", "-y", "@modelcontextprotocol/server-sequential-thinking"]
    // }
  }
}
